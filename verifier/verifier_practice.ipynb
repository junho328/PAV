{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef46ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhchoi/anaconda3/envs/gui/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:07<00:00, 33.54s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "model_path3 = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "model_path7 = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "model3 = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path3, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\",device_map=\"auto\")\n",
    "# model7 = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path7, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\",device_map=\"auto\")\n",
    "processor = AutoProcessor.from_pretrained(model_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a443c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.llm.fncall_prompts.nous_fncall_prompt import (\n",
    "    Message,\n",
    "    ContentItem,\n",
    ")\n",
    "from qwen_vl_utils import smart_resize\n",
    "import json\n",
    "from PIL import Image\n",
    "from agent_function_call import MobileUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7877de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model3\n",
    "user_query = \"\"\"\n",
    "Determine whether the action has been completed by examining the following two screenshots.\n",
    "If the action has not been completed yet, return 0. If the action has been completed, return 1.\n",
    "Action: SelectCategory 'Ala Carte & Value Meals'\n",
    "\n",
    "Think step by step and provide the final answer. And return the answer in the following format:\n",
    "<verify>\n",
    "{\n",
    "    \"action_completed\": 0,\n",
    "    \"reason\": \"The action has not been completed yet.\"\n",
    "}\n",
    "</verify>\n",
    "\"\"\"\n",
    "\n",
    "screenshot1 = 'data/mcdonalds/93/93_1.png'\n",
    "screenshot2 = 'data/mcdonalds/93/93_2.png'\n",
    "\n",
    "# The resolution of the device will be written into the system prompt. \n",
    "dummy_image1 = Image.open(screenshot1)\n",
    "dummy_image2 = Image.open(screenshot2)\n",
    "resized_height, resized_width  = smart_resize(dummy_image1.height,\n",
    "    dummy_image1.width,\n",
    "    factor=processor.image_processor.patch_size * processor.image_processor.merge_size,\n",
    "    min_pixels=processor.image_processor.min_pixels,\n",
    "    max_pixels=processor.image_processor.max_pixels,)\n",
    "\n",
    "mobile_use = MobileUse(\n",
    "    cfg={\"display_width_px\": resized_width, \"display_height_px\": resized_height}\n",
    ")\n",
    "\n",
    "message = [\n",
    "    Message(role=\"system\", content=[ContentItem(text=\"You are a helpful mobile agent and a good verifier\")]),\n",
    "    Message(role=\"user\", content=[\n",
    "        ContentItem(text=user_query),\n",
    "        ContentItem(image=f\"file://{screenshot1}\"),\n",
    "        ContentItem(image=f\"file://{screenshot2}\")\n",
    "    ]),\n",
    "]\n",
    "message = [msg.model_dump() for msg in message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f8934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text <|im_start|>system\n",
      "You are a helpful mobile agent and a good verifier<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "Determine whether the action has been completed by examining the following two screenshots.\n",
      "If the action has not been completed yet, return 0. If the action has been completed, return 1.\n",
      "Action: SelectCategory 'Ala Carte & Value Meals'\n",
      "\n",
      "Think step by step and provide the final answer. And return the answer in the following format:\n",
      "<verify>\n",
      "{\n",
      "    \"action_completed\": 0,\n",
      "    \"reason\": \"The action has not been completed yet.\"\n",
      "}\n",
      "</verify>\n",
      "<|vision_start|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "output\n",
      "<verify>\n",
      "{\n",
      "    \"action_completed\": 1,\n",
      "    \"reason\": \"The action has been completed as the 'ALA CARTE & VALUE MEALS' section is visible and accessible on the screen.\"\n",
      "}\n",
      "</verify>\n",
      "action\n",
      "{'action_completed': 1, 'reason': \"The action has been completed as the 'ALA CARTE & VALUE MEALS' section is visible and accessible on the screen.\"}\n"
     ]
    }
   ],
   "source": [
    "text = processor.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "print(\"text\",text)\n",
    "inputs = processor(text=[text], images=[dummy_image1, dummy_image2], padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "\n",
    "output_ids = model.generate(**inputs, max_new_tokens=2048)\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "print('output')\n",
    "print(output_text)\n",
    "\n",
    "# Qwen will perform action thought function call\n",
    "action = json.loads(output_text.split('<verify>\\n')[1].split('\\n</verify>')[0])\n",
    "print(\"action\")\n",
    "print(action['action_completed'])\n",
    "print(action['reason'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "906da40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier(model, screenshot1, screenshot2, action):\n",
    "    user_query = f\"\"\"\n",
    "Determine whether the action has been completed by examining the following two screenshots.\n",
    "If the action has not been completed yet, return 0. If the action has been completed, return 1.\n",
    "Action: {action}\n",
    "\n",
    "Think step by step and provide the final answer. And return the answer in the following format:\n",
    "<verify>\n",
    "{{\n",
    "    \"action_completed\": 0,\n",
    "    \"reason\": \"The action has not been completed yet.\"\n",
    "}}\n",
    "</verify>\n",
    "    \"\"\"\n",
    "\n",
    "    # The resolution of the device will be written into the system prompt. \n",
    "    dummy_image1 = Image.open(screenshot1)\n",
    "    dummy_image2 = Image.open(screenshot2)\n",
    "\n",
    "    message = [\n",
    "        Message(role=\"system\", content=[ContentItem(text=\"You are a helpful mobile agent and a good verifier\")]),\n",
    "        Message(role=\"user\", content=[\n",
    "            ContentItem(text=user_query),\n",
    "            ContentItem(image=f\"file://{screenshot1}\"),\n",
    "            ContentItem(image=f\"file://{screenshot2}\")\n",
    "        ]),\n",
    "    ]\n",
    "    message = [msg.model_dump() for msg in message]\n",
    "\n",
    "    text = processor.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    print(\"text\",text)\n",
    "    inputs = processor(text=[text], images=[dummy_image1, dummy_image2], padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=2048)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "    print('output')\n",
    "    print(output_text, '\\n')\n",
    "\n",
    "    # Qwen will perform action thought function call\n",
    "    action = json.loads(output_text.split('<verify>\\n')[1].split('\\n</verify>')[0])\n",
    "    print(f\"verify: {action['action_completed']}\")\n",
    "    print(f\"reason: {action['reason']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c62ddabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text <|im_start|>system\n",
      "You are a helpful mobile agent and a good verifier<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "Determine whether the action has been completed by examining the following two screenshots.\n",
      "If the action has not been completed yet, return 0. If the action has been completed, return 1.\n",
      "Action: SelectCategory 'Ala Carte & Value Meals'\n",
      "\n",
      "Think step by step and provide the final answer. And return the answer in the following format:\n",
      "<verify>\n",
      "{\n",
      "    \"action_completed\": 0,\n",
      "    \"reason\": \"The action has not been completed yet.\"\n",
      "}\n",
      "</verify>\n",
      "    <|vision_start|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "output\n",
      "<verify>\n",
      "{\n",
      "    \"action_completed\": 1,\n",
      "    \"reason\": \"The action has been completed as the 'ALA CARTE & VALUE MEALS' section is visible and accessible on the screen.\"\n",
      "}\n",
      "</verify> \n",
      "\n",
      "verify: 1\n",
      "reason: The action has been completed as the 'ALA CARTE & VALUE MEALS' section is visible and accessible on the screen.\n"
     ]
    }
   ],
   "source": [
    "model = model3\n",
    "screenshot1 = 'data/mcdonalds/93/93_1.png'\n",
    "screenshot2 = 'data/mcdonalds/93/93_2.png'\n",
    "action = \"SelectCategory 'Ala Carte & Value Meals'\"\n",
    "\n",
    "verifier(model, screenshot1, screenshot2, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a4af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
